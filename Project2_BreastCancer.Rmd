---
title: "Project2"
author: "Rex Cory"
date: "3/10/2021"
output:
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("C:/Users/arati/Desktop/TBANLT 560/DMBA-R-datasets/DMBA-R-datasets"))
```

```{r necessary packages, eval=FALSE, include=FALSE}
#install.packages("ROCR")##Keep

```

```{r library packages}
library(dplyr)
library(e1071)
library(klaR)
library(nnet)
library(MASS)
library(rpart)
library(mlbench)
library(randomForest)
library(party)
library(ipred)
library(ROCR)


```

```{r load data}
data(BreastCancer)
```

```{r Missing Values, ID, and Partition}
# remove missing values
BreastCancer <- na.omit(BreastCancer) 
# remove the unique identifier
BreastCancer$Id <- NULL 
# partition the data set for 80% training and 20% evaluation 
set.seed(2)

ind <- sample(2, nrow(BreastCancer), replace = TRUE, prob=c(0.8, 0.2))
```

```{r Recursive Partitioning Model}
x.rp <- rpart(Class ~ ., data=BreastCancer[ind == 1,])
x.rp.pred <- predict(x.rp, type="class", newdata=BreastCancer[ind == 2,])
x.rp.prob <- predict(x.rp, type="prob", newdata=BreastCancer[ind == 2,])
```

```{r Conditional Inference Trees}
x.ct <- ctree(Class ~ ., data=BreastCancer[ind == 1,])
x.ct.pred <- predict(x.ct, newdata=BreastCancer[ind == 2,])
x.ct.prob <-  1- unlist(treeresponse(x.ct, BreastCancer[ind == 2,]), use.names=F)[seq(1,nrow(BreastCancer[ind == 2,])*2,2)]
```

```{r Random Forest Bagging Ensemble Using Conditional Inference Trees}
x.cf <- cforest(Class ~ ., data=BreastCancer[ind == 1,], control = cforest_unbiased(mtry = ncol(BreastCancer)-2))
x.cf.pred <- predict(x.cf, newdata=BreastCancer[ind == 2,])
x.cf.prob <-  1- unlist(treeresponse(x.cf, BreastCancer[ind == 2,]), use.names=F)[seq(1,nrow(BreastCancer[ind == 2,])*2,2)]
```

```{r Bootstrap Aggregating Model}
x.ip <- bagging(Class ~ ., data=BreastCancer[ind == 1,])
x.ip.prob <- predict(x.ip, type="prob", newdata=BreastCancer[ind == 2,])
```

```{r Support Vector Network BC}
#Tune
x.svm.tune <- tune(svm, Class~., data = BreastCancer[ind == 1,], ranges = list(gamma = 2^(-8:1), cost = 2^(0:4)), tunecontrol = tune.control(sampling = "fix"))

#SVM
x.svm <- svm(Class~., data = BreastCancer[ind == 1,], cost=4, gamma=0.0625, probability = TRUE)
x.svm.prob <- predict(x.svm, type="prob", newdata=BreastCancer[ind == 2,], probability = TRUE)


```

```{r ROC Curves}
## plot ROC curves to compare the performance of the individual classifiers
##

# Output the plot to a PNG file for display on web.
png(filename="roc_curve_5_models.png", width=700, height=700)


# create an ROCR prediction object from rpart() probabilities
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")

# Draw a legend.
legend(0.6, 0.6, c('rpart', 'ctree', 'cforest','bagging','svm'), 2:6)

# ctree
x.ct.prob.rocr <- prediction(x.ct.prob, BreastCancer[ind == 2,'Class'])
x.ct.perf <- performance(x.ct.prob.rocr, "tpr","fpr")
# add=TRUE draws on the existing chart 
plot(x.ct.perf, col=3, add=TRUE)


# cforest
x.cf.prob.rocr <- prediction(x.cf.prob, BreastCancer[ind == 2,'Class'])
x.cf.perf <- performance(x.cf.prob.rocr, "tpr","fpr")
plot(x.cf.perf, col=4, add=TRUE)

# bagging
x.ip.prob.rocr <- prediction(x.ip.prob[,2], BreastCancer[ind == 2,'Class'])
x.ip.perf <- performance(x.ip.prob.rocr, "tpr","fpr")
plot.new()
plot(x.ip.perf, col=5, add=TRUE)
# svm
x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], BreastCancer[ind == 2,'Class'])
x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")

plot(x.svm.perf, col=6, add=TRUE)

# Close and save the PNG file.
dev.off()

```












